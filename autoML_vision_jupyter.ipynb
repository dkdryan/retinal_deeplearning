{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML Vision in Jupyter Notebook:\n",
    "\n",
    "# Predicting Referrable Diabetic Retinopathy using the Messidor Dataset \n",
    "\n",
    "## David K Ryan \n",
    "\n",
    "Data is publicly available from: http://www.adcis.net/en/third-party/messidor/)\n",
    "\n",
    "This returns a model that predicts referrable diabetic retinopathy from retinal images : \n",
    "\n",
    "#### Evaluation Metrics \n",
    "\n",
    "PR-AUC: 0.845  \n",
    "Precision: 75.36%  \n",
    "Recall: 75.36%   \n",
    "Using a score threshold of 0.5   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data curation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download image data from messidor website as zip file \n",
    "2. Upload zip file to google drive \n",
    "3. Unzip file within google drive \n",
    "4. Download csv with meta-data and label \n",
    "4. Rearrange images in folders according to label using notebook: google_drive_file_manipulation.ipynb\n",
    "5. Upload images from google drive to google cloud storage using notebook: drive_to_gcs.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set up a google VM instance via AI notebooks and access jupyter notebook via the console \n",
    "2. Ensure billing is enabled \n",
    "3. Enable AI console APIs \n",
    "4. Sort-out service accounts and keys! \n",
    "5. In jupyter - open a new terminal window - and ensure google sdk is in the right project id etc\n",
    "    1. gcloud init \n",
    "    2. Follow instructions to verify project and computer location \n",
    "    3. ! gcloud config set project $PROJECT_ID (note: this ensures you are in the correct project as well!)\n",
    "6. Set Service Account Role for AutoML (see code below)\n",
    "    \n",
    "See further: https://aihub.cloud.google.com/u/0/p/products%2Ffd607928-12f3-4aa1-a523-ad4431a96ed6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Code for terminal to set service account roles ####\n",
    "!gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "   --member=\"[user:your-userid@your-domain]\" \\\n",
    "   --role=\"roles/automl.admin\"\n",
    "!gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "   --member=\"[serviceAccount:service-account-name]\" \\\n",
    "   --role=\"roles/automl.editor\"\n",
    "\n",
    "#note you must have the member in the format --member=\"user:d************@gmail.com\" --role=\"roles/automl.admin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a google cloud storage bucket using the console (must be in same geographical region - uscentral1 (IOWA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure libraries are installed \n",
    "!pip install -U google-cloud-storage\n",
    "!pip install -U google-cloud-automl\n",
    "!pip install -U protobuf\n",
    "\n",
    "# Import libraries \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import the Google AutoML client library\n",
    "from google.cloud import automl_v1beta1 as automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"\"\n",
    "COMPUTE_REGION=\"\"\n",
    "BUCKET_NAME=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an AutoML client\n",
    "client = automl.AutoMlClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive the full GCP path to the project\n",
    "client = automl.AutoMlClient()\n",
    "\n",
    "# A resource that represents Google Cloud Platform location.\n",
    "project_location = f\"projects/{PROJECT_ID}/locations/us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a name for the dataset\n",
    "DATASET_NAME=\"messidor\"\n",
    "\n",
    "# Specify the image classification type for the dataset.\n",
    "dataset_metadata = {\"classification_type\": 'MULTICLASS'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset name and metadata of the dataset.\n",
    "my_dataset = {\n",
    "    \"display_name\": DATASET_NAME,\n",
    "    \"image_classification_dataset_metadata\": dataset_metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset with the dataset metadata in the region.\n",
    "response = client.create_dataset(parent = project_location, dataset=my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataset information.\n",
    "print(\"Dataset name: {}\".format(response.name))\n",
    "print(\"Dataset id: {}\".format(response.name.split(\"/\")[-1]))\n",
    "print(\"Dataset display name: {}\".format(response.display_name))\n",
    "print(\"Image classification dataset metadata:\")\n",
    "print(\"\\t{}\".format(response.image_classification_dataset_metadata))\n",
    "print(\"Dataset example count: {}\".format(response.example_count))\n",
    "\n",
    "# Save the dataset ID\n",
    "dataset_id = response.name.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full path of the dataset.\n",
    "dataset_full_id = client.dataset_path(\n",
    "    PROJECT_ID, COMPUTE_REGION, dataset_id)\n",
    "\n",
    "dataset_full_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "\n",
    "- CSV file must be in the form of gs://file/to/path.jpg, label \n",
    "- When saving CSV file - index=False, header=False \n",
    "- Bucket and model must be in the same geographical location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the location of the CSV file for the dataset\n",
    "CSV_DATASET = \"gs://\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure images \n",
    "input_config = {\"gcs_source\": {\"input_uris\": [CSV_DATASET]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from the input URI.\n",
    "response = client.import_data(name=dataset_full_id, input_config= input_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synchronous check of operation status.\n",
    "print(\"Data imported. {}\".format(response.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be verified in GCS console "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print all eligible datasets in the project \n",
    "response = client.list_datasets(parent=project_location)\n",
    "\n",
    "print(\"List of datasets:\")\n",
    "for dataset in response:\n",
    "    # Display the dataset information.\n",
    "    print(\"Dataset name: {}\".format(dataset.name))\n",
    "    print(\"Dataset id: {}\".format(dataset.name.split(\"/\")[-1]))\n",
    "    print(\"Dataset display name: {}\".format(dataset.display_name))\n",
    "    print(\"Image classification dataset metadata:\")\n",
    "    print(\"\\t{}\".format(dataset.image_classification_dataset_metadata))\n",
    "    print(\"Dataset example count: {}\\n\".format(dataset.example_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a name for your model.\n",
    "MODEL_NAME=\"messidor_dr_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training for a maximum of 1 hour\n",
    "train_budget=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model \n",
    "my_model = {\n",
    "    \"display_name\": MODEL_NAME,\n",
    "    \"dataset_id\": dataset_full_id\n",
    "    \"image_classification_model_metadata\": {\"train_budget\": train_budget}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with the model metadata in the region.\n",
    "response = client.create_model(parent=project_location, model=my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the training operation name \n",
    "print(\"Training operation name: {}\".format(response.operation.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synchronous check of operation status.\n",
    "print(\"Training done. {}\".format(response.result()))\n",
    "\n",
    "# Save the model ID\n",
    "model_id = response.result().name.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full path of the model.\n",
    "model_full_id = client.model_path(PROJECT_ID, COMPUTE_REGION, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get complete detail of the model.\n",
    "model = client.get_model(name=model_full_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve deployment state\n",
    "if model.deployment_state == \"DeploymentState.DEPLOYED\": \n",
    "    deployment_state = 'deployed'\n",
    "else: \n",
    "    deployment_state = 'undeployed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the model information.\n",
    "print(\"Model name: {}\".format(model.name))\n",
    "print(\"Model id: {}\".format(model.name.split(\"/\")[-1]))\n",
    "print(\"Model display name: {}\".format(model.display_name))\n",
    "print(\"Image classification model metadata:\")\n",
    "print(\n",
    "    \"Training budget: {}\".format(\n",
    "        model.image_classification_model_metadata.train_budget\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Training cost: {}\".format(\n",
    "        model.image_classification_model_metadata.train_cost\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Stop reason: {}\".format(\n",
    "        model.image_classification_model_metadata.stop_reason\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Base model id: {}\".format(\n",
    "        model.image_classification_model_metadata.base_model_id\n",
    "    )\n",
    ")\n",
    "print(\"Model deployment state: {}\".format(deployment_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List evaluations \n",
    "\n",
    "# Get the full path of the model.\n",
    "model_full_id = client.model_path(PROJECT_ID, COMPUTE_REGION, model_id)\n",
    "\n",
    "# List all the model evaluations in the model by applying filter.\n",
    "response = client.list_model_evaluations(parent=model_full_id)\n",
    "\n",
    "print(\"List of model evaluations:\")\n",
    "for element in response:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vision console has confusion matrix and evaluation metrics for hold-out test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch predict \n",
    "\n",
    "project_id = \"\"\n",
    "model_id = \"\"\n",
    "input_uri = \"\"\n",
    "output_uri = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input uri is the csv file saved in gs:// format which contains the gs:// for all batch-predict images \n",
    "- Input uri is a csv of gs:// only (no label). NB saved as csv with header=False, index=False\n",
    "- Output uri is the file where the json output will be saved \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the prediction client \n",
    "prediction_client = automl.PredictionServiceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full path of the model.\n",
    "model_full_id = f\"projects/{project_id}/locations/us-central1/models/{model_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_source = automl.GcsSource(input_uris=[input_uri])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction \n",
    "input_config = automl.BatchPredictInputConfig(gcs_source=gcs_source)\n",
    "gcs_destination = automl.GcsDestination(output_uri_prefix=output_uri)\n",
    "output_config = automl.BatchPredictOutputConfig(\n",
    "    gcs_destination=gcs_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = prediction_client.batch_predict(\n",
    "    name=model_full_id,\n",
    "    input_config=input_config,\n",
    "    output_config=output_config\n",
    ")\n",
    "\n",
    "print(\"Waiting for operation to complete...\")\n",
    "print(\n",
    "    f\"Batch Prediction results saved to Cloud Storage bucket. {response.result()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/dkdryan/retinal_deeplearning/blob/master/auc_messidor_automl.png?raw=true\" width=\"40%\">\n",
    "<img src=\"https://github.com/dkdryan/retinal_deeplearning/blob/master/confusion_matrix_automl.png?raw=true\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
